{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search Results:\n",
      "                 Indication  Total Cost (M$) Risk Category  similarity_score\n",
      "0  Inflammatory Conditions            147.2     High-cost          0.575739\n",
      "3           Heart Diseases             20.9     High-risk          0.398201\n",
      "\n",
      "Narrative Explanation:\n",
      " Based on the provided data, the high-cost medical condition identified is \"Inflammatory Conditions,\" with a total cost of $147.2 million. This condition falls under the high-cost category due to the substantial financial resources required for its treatment and management. The similarity score of 0.575739 indicates a relatively high correlation with this classification.\n",
      "\n",
      "On the other hand, \"Heart Diseases\" is classified as high-risk with a total cost of $20.9 million and a similarity score of 0.398201. While heart diseases are characterized as high-risk, they may not necessarily incur as high costs as inflammatory conditions, as indicated by the stark contrast in total cost between the two conditions.\n",
      "\n",
      "These findings highlight the significant financial burden associated with treating inflammatory conditions, necessitating careful resource allocation and management strategies within healthcare systems. Understanding the cost implications of different medical conditions is crucial for healthcare decision-makers to prioritize interventions effectively and allocate resources efficiently. \n",
      "\n",
      "In conclusion, the analysis demonstrates that \"Inflammatory Conditions\" stand out as high-cost medical conditions based on the provided data, emphasizing the importance of considering both cost and risk factors when evaluating the economic impact of specific health conditions.\n",
      "\n",
      "Table Statistics:\n",
      " {\n",
      "  \"numeric_stats\": {\n",
      "    \"Total Cost (M$)\": {\n",
      "      \"mean\": 51.5,\n",
      "      \"median\": 22.7,\n",
      "      \"min\": 19.2,\n",
      "      \"max\": 147.2,\n",
      "      \"std\": 54.73476957108707\n",
      "    }\n",
      "  },\n",
      "  \"categorical_stats\": {\n",
      "    \"Indication\": {\n",
      "      \"Inflammatory Conditions\": 0.2,\n",
      "      \"Cancer\": 0.2,\n",
      "      \"Migraine Headaches\": 0.2,\n",
      "      \"Heart Diseases\": 0.2,\n",
      "      \"Diabetes\": 0.2\n",
      "    },\n",
      "    \"Risk Category\": {\n",
      "      \"High-cost\": 0.2,\n",
      "      \"Critical\": 0.2,\n",
      "      \"Moderate\": 0.2,\n",
      "      \"High-risk\": 0.2,\n",
      "      \"Chronic\": 0.2\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "\n",
    "class TableRAG:\n",
    "    def __init__(self, embedding_model='all-MiniLM-L6-v2', openai_api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize TableRAG with embedding model and optional OpenAI client\n",
    "        \n",
    "        Args:\n",
    "            embedding_model (str): Sentence transformer model\n",
    "            openai_api_key (str): OpenAI API key for generation\n",
    "        \"\"\"\n",
    "        # Embedding model for table semantic representation\n",
    "        self.embedding_model = SentenceTransformer(embedding_model)\n",
    "        \n",
    "        # OpenAI client for generation (optional)\n",
    "        if openai_api_key:\n",
    "            self.openai_client = OpenAI(api_key=openai_api_key)\n",
    "        else:\n",
    "            self.openai_client = None\n",
    "\n",
    "    def parse_table(self, table_data, source_type='dataframe'):\n",
    "        \"\"\"\n",
    "        Parse table from various sources\n",
    "        \n",
    "        Args:\n",
    "            table_data: Input table data\n",
    "            source_type (str): Type of input source\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Parsed and standardized DataFrame\n",
    "        \"\"\"\n",
    "        if source_type == 'dataframe':\n",
    "            return table_data\n",
    "        elif source_type == 'csv':\n",
    "            return pd.read_csv(table_data)\n",
    "        elif source_type == 'excel':\n",
    "            return pd.read_excel(table_data)\n",
    "        elif source_type == 'json':\n",
    "            return pd.DataFrame(json.loads(table_data))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported source type\")\n",
    "\n",
    "    def generate_table_embeddings(self, dataframe):\n",
    "        \"\"\"\n",
    "        Generate semantic embeddings for table rows\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            dict: Embeddings for each row\n",
    "        \"\"\"\n",
    "        # Convert each row to a textual representation\n",
    "        row_texts = dataframe.apply(\n",
    "            lambda row: ' | '.join(row.astype(str)), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self.embedding_model.encode(row_texts.tolist())\n",
    "        \n",
    "        return {\n",
    "            'embeddings': embeddings,\n",
    "            'row_texts': row_texts\n",
    "        }\n",
    "\n",
    "    def semantic_table_search(self, dataframe, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Perform semantic search across table rows\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input DataFrame\n",
    "            query (str): Search query\n",
    "            top_k (int): Number of top results to return\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Top matching rows\n",
    "        \"\"\"\n",
    "        # Generate table embeddings\n",
    "        table_embeddings = self.generate_table_embeddings(dataframe)\n",
    "        \n",
    "        # Embed query\n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity([query_embedding], table_embeddings['embeddings'])[0]\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        # Return top matching rows with similarity scores\n",
    "        results = dataframe.iloc[top_indices].copy()\n",
    "        results['similarity_score'] = similarities[top_indices]\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def generate_narrative(self, query, retrieved_rows):\n",
    "        \"\"\"\n",
    "        Generate narrative explanation using retrieved rows\n",
    "        \n",
    "        Args:\n",
    "            query (str): Original query\n",
    "            retrieved_rows (pd.DataFrame): Retrieved matching rows\n",
    "        \n",
    "        Returns:\n",
    "            str: Generated narrative explanation\n",
    "        \"\"\"\n",
    "        if self.openai_client is None:\n",
    "            raise ValueError(\"OpenAI API key not provided\")\n",
    "        \n",
    "        # Convert retrieved rows to string representation\n",
    "        context = retrieved_rows.to_string(index=False)\n",
    "        \n",
    "        # Construct prompt\n",
    "        prompt = f\"\"\"\n",
    "        Context: {context}\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Based on the provided context, generate a comprehensive and \n",
    "        insightful narrative that directly addresses the query. \n",
    "        Explain the key findings and provide relevant insights.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert data analyst\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def analyze_table_statistics(self, dataframe):\n",
    "        \"\"\"\n",
    "        Provide comprehensive statistical analysis of the table\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "        Returns:\n",
    "            dict: Statistical summary\n",
    "        \"\"\"\n",
    "        # Numeric column analysis\n",
    "        numeric_columns = dataframe.select_dtypes(include=[np.number]).columns\n",
    "        numeric_stats = dataframe[numeric_columns].agg([\n",
    "            'mean', 'median', 'min', 'max', 'std'\n",
    "        ]).to_dict()\n",
    "        \n",
    "        # Categorical column analysis\n",
    "        categorical_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "        categorical_stats = {\n",
    "            col: dataframe[col].value_counts(normalize=True).to_dict()\n",
    "            for col in categorical_columns\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'numeric_stats': numeric_stats,\n",
    "            'categorical_stats': categorical_stats\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Example usage with medical indications data\n",
    "    medical_data = pd.DataFrame([\n",
    "        ['Inflammatory Conditions', 147.2, 'High-cost'],\n",
    "        ['Cancer', 47.5, 'Critical'],\n",
    "        ['Migraine Headaches', 22.7, 'Moderate'],\n",
    "        ['Heart Diseases', 20.9, 'High-risk'],\n",
    "        ['Diabetes', 19.2, 'Chronic']\n",
    "    ], columns=['Indication', 'Total Cost (M$)', 'Risk Category'])\n",
    "\n",
    "    # Initialize TableRAG (replace with your OpenAI API key)\n",
    "    table_rag = TableRAG(openai_api_key='')\n",
    "\n",
    "    # Perform semantic search\n",
    "    query = \"What are high-cost medical conditions?\"\n",
    "    search_results = table_rag.semantic_table_search(\n",
    "        medical_data, \n",
    "        query, \n",
    "        top_k=2\n",
    "    )\n",
    "    print(\"Semantic Search Results:\\n\", search_results)\n",
    "\n",
    "    # Generate narrative explanation\n",
    "    narrative = table_rag.generate_narrative(query, search_results)\n",
    "    print(\"\\nNarrative Explanation:\\n\", narrative)\n",
    "\n",
    "    # Perform statistical analysis\n",
    "    stats = table_rag.analyze_table_statistics(medical_data)\n",
    "    print(\"\\nTable Statistics:\\n\", json.dumps(stats, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
